{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from IPython.display import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from prettytable import PrettyTable   \n",
    "from astropy.table import Table, Column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Conv2D, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Load Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.1: Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▋                                                                             | 6/104 [00:00<00:01, 55.99it/s]"
     ]
    }
   ],
   "source": [
    "''' \n",
    "*---------------------- LOAD_SAMPLE_DATA ------------------------*\n",
    "|     Function: imread()                                         |\n",
    "|             Purpose: Read an image as a numpy ndarray          |\n",
    "|     Arguments:                                                 |\n",
    "|             path: Complete path to image file                  |\n",
    "|     Return:                                                    |\n",
    "|             dataset: Numpy ndarray of pixel values             |\n",
    "*----------------------------------------------------------------*\n",
    "'''\n",
    "path = ('Dataset/Training Data')\n",
    "data = [os.path.join(dp, f) for dp, dn, filenames in os.walk(path) for f in filenames if (os.path.splitext(f)[1] == '.jpg' or os.path.splitext(f)[1] == '.png')]\n",
    "\n",
    "training_data=[]\n",
    "\n",
    "for image_name in tqdm(data):\n",
    "    training_data.append((cv2.imread(image_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = []\n",
    "index=0\n",
    "for i in data:\n",
    "    if(\"apple\" in i):\n",
    "        training_dataset.append([training_data[index],\"apple\"])\n",
    "    elif(\"bag\" in i):\n",
    "        training_dataset.append([training_data[index],\"bag\"])\n",
    "    elif(\"circle\" in i):\n",
    "        training_dataset.append([training_data[index],\"circle\"])\n",
    "    elif(\"door\" in i):\n",
    "        training_dataset.append([training_data[index],\"door\"])   \n",
    "    elif(\"eye\" in i):\n",
    "        training_dataset.append([training_data[index],\"eye\"])        \n",
    "    elif(\"flower\" in i):\n",
    "        training_dataset.append([training_data[index],\"flower\"])        \n",
    "    elif(\"glass\" in i):\n",
    "        training_dataset.append([training_data[index],\"glass\"])        \n",
    "    elif(\"house\" in i):\n",
    "        training_dataset.append([training_data[index],\"house\"])        \n",
    "    elif(\"ice cream\" in i):\n",
    "        training_dataset.append([training_data[index],\"ice cream\"])\n",
    "    elif(\"jug\" in i):\n",
    "        training_dataset.append([training_data[index],\"jug\"])\n",
    "    elif(\"kite\" in i):\n",
    "        training_dataset.append([training_data[index],\"kite\"])   \n",
    "    elif(\"leaf\" in i):\n",
    "        training_dataset.append([training_data[index],\"leaf\"])        \n",
    "    elif(\"mango\" in i):\n",
    "        training_dataset.append([training_data[index],\"mango\"])        \n",
    "    elif(\"net\" in i):\n",
    "        training_dataset.append([training_data[index],\"net\"])        \n",
    "    elif(\"number One\" in i):\n",
    "        training_dataset.append([training_data[index],\"number One\"])        \n",
    "    elif(\"pencil\" in i):\n",
    "        training_dataset.append([training_data[index],\"pencil\"])\n",
    "    elif(\"letter Q\" in i):\n",
    "        training_dataset.append([training_data[index],\"letter Q\"])\n",
    "    elif(\"rectangle\" in i):\n",
    "        training_dataset.append([training_data[index],\"rectangle\"])   \n",
    "    elif(\"star\" in i):\n",
    "        training_dataset.append([training_data[index],\"star\"])        \n",
    "    elif(\"triangle\" in i):\n",
    "        training_dataset.append([training_data[index],\"triangle\"])        \n",
    "    elif(\"umbrella\" in i):\n",
    "        training_dataset.append([training_data[index],\"umbrella\"])        \n",
    "    elif(\"vehicle\" in i):\n",
    "        training_dataset.append([training_data[index],\"vehicle\"])        \n",
    "    elif(\"watch\" in i):\n",
    "        training_dataset.append([training_data[index],\"watch\"])\n",
    "    elif(\"letter X\" in i):\n",
    "        training_dataset.append([training_data[index],\"letter X\"])\n",
    "    elif(\"letter y\" in i):\n",
    "        training_dataset.append([training_data[index],\"letter y\"])           \n",
    "    else:\n",
    "        training_dataset.append([training_data[index],\"letter z\"])\n",
    "    index=index+1\n",
    "training_dataset=pd.DataFrame(training_dataset,columns=[\"Pixel Values\",\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.2: Load Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "*---------------------- LOAD_SAMPLE_DATA ------------------------*\n",
    "|     Function: imread()                                         |\n",
    "|             Purpose: Read an image as a numpy ndarray          |\n",
    "|     Arguments:                                                 |\n",
    "|             path: Complete path to image file                  |\n",
    "|     Return:                                                    |\n",
    "|             dataset: Numpy ndarray of pixel values             |\n",
    "*----------------------------------------------------------------*\n",
    "'''\n",
    "path = ('Dataset/Testing Data')\n",
    "data = [os.path.join(dp, f) for dp, dn, filenames in os.walk(path) for f in filenames if (os.path.splitext(f)[1] == '.jpg' or os.path.splitext(f)[1] == '.png')]\n",
    "\n",
    "testing_data=[]\n",
    "\n",
    "for image_name in tqdm(data):\n",
    "    testing_data.append((cv2.imread(image_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = []\n",
    "index=0\n",
    "for i in data:\n",
    "    if(\"apple\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"apple\"])\n",
    "    elif(\"bag\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"bag\"])\n",
    "    elif(\"circle\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"circle\"])\n",
    "    elif(\"door\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"door\"])   \n",
    "    elif(\"eye\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"eye\"])        \n",
    "    elif(\"flower\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"flower\"])        \n",
    "    elif(\"glass\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"glass\"])        \n",
    "    elif(\"house\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"house\"])        \n",
    "    elif(\"ice cream\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"ice cream\"])\n",
    "    elif(\"jug\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"jug\"])\n",
    "    elif(\"kite\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"kite\"])   \n",
    "    elif(\"leaf\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"leaf\"])        \n",
    "    elif(\"mango\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"mango\"])        \n",
    "    elif(\"net\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"net\"])        \n",
    "    elif(\"number One\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"number One\"])        \n",
    "    elif(\"pencil\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"pencil\"])\n",
    "    elif(\"letter Q\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"letter Q\"])\n",
    "    elif(\"rectangle\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"rectangle\"])   \n",
    "    elif(\"star\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"star\"])        \n",
    "    elif(\"triangle\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"triangle\"])        \n",
    "    elif(\"umbrella\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"umbrella\"])        \n",
    "    elif(\"vehicle\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"vehicle\"])        \n",
    "    elif(\"watch\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"watch\"])\n",
    "    elif(\"letter X\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"letter X\"])\n",
    "    elif(\"letter y\" in i):\n",
    "        testing_dataset.append([testing_data[index],\"letter y\"])           \n",
    "    else:\n",
    "        testing_dataset.append([testing_data[index],\"letter z\"])\n",
    "    index=index+1\n",
    "testing_dataset=pd.DataFrame(testing_dataset,columns=[\"Pixel Values\",\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Understand and Pre-process Sample Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.1: Understand Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand Sample Data\n",
    "\n",
    "print(\"\\n\\nAttributes in Training Data:\")\n",
    "print(\"============================\\n\")\n",
    "\n",
    "print(training_dataset.columns)\n",
    "\n",
    "print(\"\\n\\nNumber of Instances in Training Data:\",training_dataset[\"Label\"].count())\n",
    "print(\"==========================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.2: Understand Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand Sample Data\n",
    "\n",
    "print(\"\\n\\nAttributes in Testing Data:\")\n",
    "print(\"===========================\\n\")\n",
    "\n",
    "print(testing_dataset.columns)\n",
    "\n",
    "print(\"\\n\\nNumber of Instances in Testing Data:\",testing_dataset[\"Label\"].count())\n",
    "print(\"=========================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.3: Pre-process Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pixels in enumerate(training_dataset[\"Pixel Values\"]):\n",
    "    training_dataset[\"Pixel Values\"][pixels[0]]=cv2.resize(pixels[1],(45,45),interpolation=cv2.INTER_AREA)\n",
    "print(\"\\n\\nPre-processed Training Data:\")\n",
    "print(\"============================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3.4: Pre-process Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pixels in enumerate(testing_dataset[\"Pixel Values\"]):\n",
    "    testing_dataset[\"Pixel Values\"][pixels[0]]=cv2.resize(pixels[1],(45,45),interpolation=cv2.INTER_AREA)\n",
    "print(\"\\n\\nPre-processed Testing Data:\")\n",
    "print(\"===========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Convert Output to Machine Understandable Format (Numerical Representation) using Label Encoding Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.1: Train the Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Label Encoder\n",
    "\n",
    "''' \n",
    "*------------------ TRAIN_LABEL_ENCODER --------------------*\n",
    "|        Function: Fit()                                    |\n",
    "|              Purpose: Fit or Train the Label Encoder      |\n",
    "|        Arguments:                                         |\n",
    "|               Labels: Target Values                       |\n",
    "|        Return:                                            |\n",
    "|               Instance: Returns an instance of self       |\n",
    "*-----------------------------------------------------------*\n",
    "''' \n",
    "\n",
    "# Label\n",
    "label = pd.DataFrame({\"Label\":[\"apple\",\"bag\",\"circle\",\"door\",\"eye\",\"flower\",\"glass\",\"house\",\"ice cream\",\"jug\",\"kite\",\"leaf\",\"mango\",\"net\",\"number One\",\"pencil\",\"letter Q\",\"rectangle\",\"star\",\"triangle\",\"star\",\"triangle\",\"umbrella\",\"vehicle\",\"watch\",\"letter X\",\"letter y\",\"letter z\"]})\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Train the Label Encoders\n",
    "label_encoder.fit(np.ravel(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.2: Convert Output of Training Data to Machine Understandable Format (Numerical Representation) using Label Encoder (Trained in Step 4.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding of the Output\n",
    "\n",
    "''' \n",
    "*------------------ LABEL_ENCODE_OUTPUT --------------------*\n",
    "|        Function: Transform()                              |\n",
    "|              Purpose: Transform Input (Categorical)       |\n",
    "|                       into Numerical Representation       |\n",
    "|        Arguments:                                         |\n",
    "|              Attribute: Target values                     |\n",
    "|        Return:                                            |\n",
    "|              Attribute: Numerical Representation          |\n",
    "*-----------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "training_data_encoded_output = training_dataset.copy()\n",
    "original_training_data = training_dataset.copy()\n",
    "\n",
    "# Transform Output of into Numerical Representation\n",
    "print(\"\\n\\nLabel Attribute After Label Encoding:\")\n",
    "print(\"=====================================\\n\")\n",
    "training_dataset[\"Encoded_Label\"] = label_encoder.transform(training_dataset['Label'])\n",
    "pd.set_option('max_rows', 104)\n",
    "print(training_dataset[[\"Label\", \"Encoded_Label\"]])\n",
    "training_data_encoded_output[['Pixel Values', 'Label']] = training_dataset[['Pixel Values', 'Encoded_Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4.3: Convert Output of Testing Data to Machine Understandable Format (Numerical Representation) using Label Encoder (Trained in Step 4.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding of the Output\n",
    "\n",
    "''' \n",
    "*------------------ LABEL_ENCODE_OUTPUT --------------------*\n",
    "|        Function: Transform()                              |\n",
    "|              Purpose: Transform Input (Categorical)       |\n",
    "|                       into Numerical Representation       |\n",
    "|        Arguments:                                         |\n",
    "|              Attribute: Target values                     |\n",
    "|        Return:                                            |\n",
    "|              Attribute: Numerical Representation          |\n",
    "*-----------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "testing_data_encoded_output = testing_dataset.copy()\n",
    "original_testing_data = testing_dataset.copy()\n",
    "\n",
    "# Transform Output of into Numerical Representation\n",
    "print(\"\\n\\nLabel Attribute After Label Encoding:\")\n",
    "print(\"=====================================\\n\")\n",
    "testing_dataset[\"Encoded_Label\"] = label_encoder.transform(testing_dataset['Label'])\n",
    "pd.set_option('max_rows', 26)\n",
    "print(testing_dataset[[\"Label\", \"Encoded_Label\"]])\n",
    "testing_data_encoded_output[['Pixel Values', 'Label']] = testing_dataset[['Pixel Values', 'Encoded_Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Feature Extraction using Pixel Values based Approach (Converting Input to Machine Understandable Format (Numerical Representation)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5.1: Extract Pixel Values based Features from Input (Image) of Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pixels in enumerate(training_data_encoded_output[\"Pixel Values\"]):\n",
    "    training_data_encoded_output[\"Pixel Values\"][pixels[0]]=pixels[1].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\nPixel Values Extracted from Input of Training Data (Numerical Representation):\")\n",
    "print(\"=============================================================================\\n\")\n",
    "print(training_data_encoded_output[\"Pixel Values\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.2: Extract Pixel Values based Features from Input (Image) of Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pixels in enumerate(testing_data_encoded_output[\"Pixel Values\"]):\n",
    "    testing_data_encoded_output[\"Pixel Values\"][pixels[0]]=pixels[1].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\nPixel Values Extracted from Input of Testing Data (Numerical Representation):\")\n",
    "print(\"=============================================================================\\n\")\n",
    "print((testing_data_encoded_output[\"Pixel Values\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5.3: Saving Features in Excel / CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.3.1 Saving Training Features in Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Features \n",
    "training_data_encoded_output.to_excel('Files/training-features.xlsx', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5.3.2 Saving Testing Features in Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "testing_data_encoded_output.to_excel('Files/testing-features.xlsx', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Execute the Training Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.1: Load Training Data in Machine Understandable Format (Numerical Representation) (Saved in Step 5.3.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*---------------------- LOAD_TRAINING_DATASET -------------------*\n",
    "| Function : read_excel()                                        |\n",
    "| Purpose : Read a dataset in Excel file format                  |\n",
    "| Arguments :                                                    |\n",
    "| path : Path to dataset file                                    |\n",
    "| dataset : Dataset file name                                    |\n",
    "| Return :                                                       | \n",
    "| dataset : Dataset in DataFrame format                          |\n",
    "*----------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "training_data = pd.read_excel(r'Files/training-features.xlsx')\n",
    "for features in enumerate(training_data[\"Pixel Values\"]):\n",
    "    training_data[\"Pixel Values\"][features[0]]=np.fromstring(features[1][1:-1], dtype=np.uint8, sep=',')\n",
    "print(\"\\n\\nTraining Data:\")\n",
    "print(\"==============\\n\")\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.2: Splitting Training Data into Input Feature Vectors and Outputs / Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Input Vectors and Outputs / Labels of Training Data\n",
    "\n",
    "'''\n",
    "*---------------- SPLIT_INPUT_VECTORS_AND_LABELS --------------*\n",
    "|        Function: iloc()                                      |\n",
    "|            Purpose: Splitting Input Vector and Labels        |\n",
    "|        Arguments:                                            |\n",
    "|            Attribute: Name or Location Attribute to Split    |\n",
    "|        Return:                                               |\n",
    "|            Attribute: Split Attributes                       |\n",
    "*--------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Training Data:\")\n",
    "print(\"==================================================\\n\")\n",
    "input_vector_train = training_data.iloc[: , :-1]\n",
    "print(input_vector_train)\n",
    "\n",
    "print(\"\\n\\nOutputs/Labels of Training Data:\")\n",
    "print(\"================================\\n\")\n",
    "print(\"    Label\")\n",
    "output_label_train = training_data.iloc[: ,-1]\n",
    "print(output_label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.3: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Neural Network\n",
    "\n",
    "print(\"\\n\\nTraining the Neural Network on Training Data\")\n",
    "print(\"=============================================\\n\")\n",
    "input_train=np.zeros((len(input_vector_train[\"Pixel Values\"]),6075),dtype=np.uint8)\n",
    "\n",
    "for input_vector in enumerate(input_vector_train[\"Pixel Values\"]):\n",
    "    input_train[input_vector[0]]=input_vector[1]\n",
    "\n",
    "X = input_train\n",
    "Y = output_label_train\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 45, 45, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 45, 45, 3)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Model layers\n",
    "model.add(Conv2D(128, kernel_size=1, activation=\"relu\", input_shape=(45, 45, 3)))\n",
    "model.add(Conv2D(32, kernel_size=1, activation=\"relu\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(26, activation=\"softmax\"))\n",
    "\n",
    "# Compile model using accuracy to measure model performance\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for loss\n",
    "print(\"\\n\\nTraining and Validation Loss:\")\n",
    "print(\"=============================\\n\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 7)\n",
    "plt.plot(history.history['loss'] ,linewidth = 4, color=\"b\", linestyle=':')\n",
    "plt.plot(history.history['val_loss'],linewidth = 2, color=\"r\")\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Loss', 'Validation Loss'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for accuracy\n",
    "print(\"\\n\\nTraining and Validation Accuracy:\")\n",
    "print(\"================================\\n\")\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(10, 7)\n",
    "plt.plot(history.history['accuracy'] ,linewidth = 4, color=\"g\", linestyle=':')\n",
    "plt.plot(history.history['val_accuracy'],linewidth = 2, color=\"y\")\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6.4: Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "\n",
    "model.save('myTrained_Model.h5')\n",
    "print(\"\\nTrained Model is Saved!!\")\n",
    "print(\"=========================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Execute the Testing Phase "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.1: Load Testing Data in Machine Understander Format (Numerical Representation) (Saved in Step 5.3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "*---------------------- LOAD_TRAINING_DATASET -------------------*\n",
    "| Function : read_excel()                                        |\n",
    "| Purpose : Read a dataset in Excel file format                  |\n",
    "| Arguments :                                                    |\n",
    "| path : Path to dataset file                                    |\n",
    "| dataset : Dataset file name                                    |\n",
    "| Return :                                                       | \n",
    "| dataset : Dataset in DataFrame format                          |\n",
    "*----------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "testing_data = pd.read_excel(r'files/testing-features.xlsx')\n",
    "for features in enumerate(testing_data[\"Pixel Values\"]):\n",
    "    testing_data[\"Pixel Values\"][features[0]]=np.fromstring(features[1][1:-1], dtype=np.uint8, sep=',')\n",
    "print(\"\\n\\nTesting Data:\")\n",
    "print(\"==============\\n\")\n",
    "print(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step:7.2 Load the Model (Saved in Step 6.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "model = load_model(\"Trained_Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7.3: Evaluate the Machine Learning Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.3.1: Splitting Testing Data into Input Feature Vectors and Outputs / Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Input Vectors and Outputs/Labels of Testing Data\n",
    "\n",
    "'''\n",
    "*---------------- SPLIT_INPUT_VECTORS_AND_LABELS --------------*\n",
    "|        Function: iloc()                                      |\n",
    "|            Purpose: Splitting Input Vector and Labels        |\n",
    "|        Arguments:                                            |\n",
    "|            Attribute: Name or Location Attribute to Split    |\n",
    "|        Return:                                               |\n",
    "|            Attribute: Split Attributes                       |\n",
    "*--------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nInputs Vectors (Feature Vectors) of Testing Data:\")\n",
    "print(\"=================================================\\n\")\n",
    "input_vector_test = testing_data.iloc[: , :-1]\n",
    "print(input_vector_test)\n",
    "input_test=np.zeros((len(input_vector_test[\"Pixel Values\"]),6075),dtype=np.uint8)\n",
    "\n",
    "for input_vector in enumerate(input_vector_test[\"Pixel Values\"]):\n",
    "    input_test[input_vector[0]]=input_vector[1]\n",
    "print(\"\\n\\nOutputs/Labels of Testing Data:\")\n",
    "print(\"==============================\\n\")\n",
    "print(\"    Label\")\n",
    "output_label_test = testing_data.iloc[: ,-1]\n",
    "print(output_label_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.3.2: Evaluate the Model (Make Predictions on Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Machine Learning Model\n",
    "''' \n",
    "*--------------------- EVALUATE_MACHINE_LEARNING_MODEL ----------------------*\n",
    "|       Function: Predict()                                                  |\n",
    "|             Purpose: Make a Prediction using Algorithm on Test Data        |\n",
    "|       Arguments:                                                           |\n",
    "|            Testing Data: Provide Test data to the Trained Model            |\n",
    "|       Return:                                                              |\n",
    "|            Predictions: Model return Predictions                           |\n",
    "*----------------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Provide Test data to the Trained Model\n",
    "\n",
    "input_test = np.array(input_test)\n",
    "output_label_test = np.array(output_label_test)\n",
    "\n",
    "input_test = input_test.reshape(input_test.shape[0], 45, 45, 3)\n",
    "\n",
    "model_predictions = model.predict(input_test)\n",
    "model_predictions2 = model_predictions.copy()\n",
    "testing_data.copy(deep=True)\n",
    "pd.options.mode.chained_assignment = None\n",
    "a=0\n",
    "list = []\n",
    "for i in model_predictions:\n",
    "    model_predictions[a] = np.argmax(i)\n",
    "    list.append(model_predictions[a][0].astype(\"int32\"))\n",
    "    a=a+1\n",
    "    \n",
    "testing_data[\"Predictions\"] = list\n",
    "\n",
    "list = testing_data \n",
    "print(\"\\n\\nPredictions Returned by trained_model:\")\n",
    "print(\"======================================\\n\")\n",
    "print(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7.3.3: Evaluate the Model (Calculate Accuracy Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Accuracy Score\n",
    "\n",
    "''' \n",
    "/*------------------------ CALCULATE_ACCURACY_SCORE -------------------*\n",
    "|          Function: accuracy_score()                                  |\n",
    "|                Purpose: Evaluate the algorithm on Testing data       |\n",
    "|          Arguments:                                                  |\n",
    "|                Prediction: Predicted values                          |\n",
    "|                Label: Actual values                                  |\n",
    "|          Return:                                                     |\n",
    "|                Accuracy: Accuracy Score                              |\n",
    "*----------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Calculate the Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "model_accuracy_score = accuracy_score(list[\"Label\"],list[\"Predictions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Execute the Application Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.1: Take Input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Input from User\n",
    "\n",
    "''' \n",
    "*----------------------- TAKE_USER_INPUT ------------------------*\n",
    "|     Function: imread()                                         |\n",
    "|             Purpose: Read an image as a numpy ndarray          |\n",
    "|     Arguments:                                                 |\n",
    "|             path: Complete path to image file                  |\n",
    "|     Return:                                                    |\n",
    "|             dataset: Numpy ndarray of pixel values             |\n",
    "*----------------------------------------------------------------*\n",
    "'''\n",
    "application_window = tk.Tk()\n",
    "# Build a list of tuples for each file type the file dialog should display\n",
    "\n",
    "my_filetypes = [('all files', '.*'), ('text files', '.txt')]\n",
    "\n",
    "# Ask the user to select a single file name\n",
    "user_file = filedialog.askopenfilename(parent=application_window,\n",
    "                                    initialdir=os.getcwd(),\n",
    "                                    title=\"Please select an Image to detect gender:\",\n",
    "                                    filetypes=my_filetypes)\n",
    "application_window.destroy()\n",
    "user_input=cv2.imread(user_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.2:  Convert User Input into Feature Vector using Pixel Values based Approach (Exactly Same as Feature Vectors of Training Data and Testing Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert User Input into Feature Vector\n",
    "user_input = cv2.resize(user_input,(45,45),interpolation=cv2.INTER_AREA)\n",
    "user_input = user_input.flatten()\n",
    "print(\"\\n\\nUser Input Feature Vector:\")\n",
    "print(\"==========================\\n\")\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3: Make Prediction on Unseen Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3.1: Load the Model (Saved in Step 6.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*----------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                          |\n",
    "|             Purpose: Method to Load Previously Saved Model        |\n",
    "|         Arguments:                                                |\n",
    "|               Model: Trained Model                                |\n",
    "|         Return:                                                   |\n",
    "|               File: Saved Model will be Loaded in Memory          |\n",
    "*-------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "model = load_model(\"Trained_Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3.2: Apply Model on Feature Vector of Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of Unseen Instance\n",
    "\n",
    "''' \n",
    "*----------------------------  MODEL_PREDICTION --------------------------*\n",
    "|           Function: predict()                                           |\n",
    "|                 Purpose: Use Trained Model to Predict the Output        |\n",
    "|                          of Unseen Instances                            |\n",
    "|           Arguments:                                                    |\n",
    "|                 User Data: Label Encoded Feature Vector of              |\n",
    "|                            Unseen Instances                             |\n",
    "|           Return:                                                       |\n",
    "|                 Survival: label                                         |\n",
    "*-------------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Make a Prediction on Unseen Data\n",
    "user_input = np.array(user_input)\n",
    "user_input = user_input.reshape(1, 45, 45, 3)\n",
    "predicted_label = model.predict([user_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8.3.3: Return Prediction to the User "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = np.argmax(predicted_label)\n",
    "predicted_label = label_encoder.inverse_transform([predicted_label])\n",
    "\n",
    "print(\"\\n\\n==============\")\n",
    "print(str(predicted_label[0][0].upper() + \" : \" + predicted_label))\n",
    "print(\"==============\\n\\n\")"
   ]
  },
 {
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
